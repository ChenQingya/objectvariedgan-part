# 理解torch.mean()
# 当维度为-1时，表示在最后一维！！！

import torch
a = torch.randn(4, 4)
a
# Out[5]:
# tensor([[-0.1107, -0.8867, -0.3839, -0.0327],
#         [-0.1580, -0.5942, -0.1254,  1.2526],
#         [-0.8005, -0.4227, -0.7724, -0.1312],
#         [-0.1823,  0.7397,  1.0533,  0.8387]])
a.mean(-1)
# Out[6]: tensor([-0.3535,  0.0937, -0.5317,  0.6123])


b = torch.rand(4,3)
b
# Out[8]:
# tensor([[0.4195, 0.6075, 0.4802],
#         [0.1399, 0.8017, 0.2161],
#         [0.2439, 0.9836, 0.9017],
#         [0.7338, 0.1918, 0.6820]])
b.mean(-1)
# Out[9]: tensor([0.5024, 0.3859, 0.7097, 0.5359])
b.mean()
# Out[10]: tensor(0.5335)
b.mean(0)
# Out[11]: tensor([0.3843, 0.6462, 0.5700])
b.mean(1)
# Out[12]: tensor([0.5024, 0.3859, 0.7097, 0.5359])
# 恰好等于mean(-1),是因为此时最后一维刚好也是第一维
# 维度是从0开始，即第0维、第一维、第二维...以此类推
b
# Out[13]:
# tensor([[0.4195, 0.6075, 0.4802],
#         [0.1399, 0.8017, 0.2161],
#         [0.2439, 0.9836, 0.9017],
#         [0.7338, 0.1918, 0.6820]])
b.mean(-1)
# Out[14]: tensor([0.5024, 0.3859, 0.7097, 0.5359])

import torch
c = torch.rand(2,3,4)
c
# Out[4]:
# tensor([[[0.3819, 0.4414, 0.8479, 0.9726],
#          [0.1147, 0.0595, 0.8538, 0.2071],
#          [0.0011, 0.5355, 0.5220, 0.3522]],
#         [[0.9552, 0.9806, 0.3258, 0.5489],
#          [0.1201, 0.8401, 0.5475, 0.7137],
#          [0.3127, 0.4955, 0.1101, 0.2280]]])
c.mean(-1)
# Out[5]:
# tensor([[0.6610, 0.3088, 0.3527],
#         [0.7026, 0.5554, 0.2866]])
# 其中0.6610 = (0.3819+0.4414+0.8479+0.9726)/4
cmean = c.mean(-1)
cmean.size()
# Out[7]: torch.Size([2, 3])
